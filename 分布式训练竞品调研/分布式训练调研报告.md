## 一、国内外分布式训练产品列表

| 类别     | 序号 | 平台（产品）名称        | 网址                                                         |
| -------- | ---- | ----------------------- | ------------------------------------------------------------ |
| 国内产品 | 1    | 华为AI开发平台ModelArts | <https://support.huaweicloud.com/tg-modelarts/modelarts_15_0007.html> |
|          | 2    | 华为云容器实例CCI       | <https://support.huaweicloud.com/api-cci/cci_02_3141.html>   |
|          | 3    | 阿里机器学习平台PAI     | <https://help.aliyun.com/document_detail/165137.html?spm=a2c4g.11186623.6.658.3561395frfXWth> |
|          | 4    | UCloud AI训练服务平台   | <https://docs.ucloud.cn/uai-train/introduction/distributed-job> |
|          | 5    | 腾讯智能钛机器学习平台  | <https://cloud.tencent.com/document/product/851/40124>       |
|          | 6    | 美团云深度学习平台      | <https://www.mtyun.com/doc/products/ai/dls/TensorFlow-distribution> |
|          | 7    | 小米生态云深度学习平台  | <http://docs.api.xiaomi.com/zh/cloud-ml/trainjob/0501_use_distributed_training.html> |
|          | 8    | 百度飞浆                | <https://www.paddlepaddle.org.cn/documentation/docs/zh/api_guides/low_level/distributed/index.html> |
|          | 9    | 才云分布式学习平台      | <https://caicloud.io/methods/distributed?word_con=A2>        |
|          | 10   | 浪潮AIStation 训练平台  | <https://www.inspur.com/lcjtww/2315499/2315503/2378047/2378048/2378054/2378932/index.html> |
|          | 11   | 百度机器学习BML         | <https://cloud.baidu.com/doc/BML/s/pjxbisnm8>                |
|          | 12   | 京东-DAS平台            | https://cf.jd.com/pages/viewpage.action?pageId=246116591     |
|          | 13   | 京东-Lambda平台         | http://lambda.jdfmgt.com                                     |
|          | 14   | 滴滴云                  | https://www.didiyun.com                                      |
| 国外产品 | 1    | 亚马逊Deeplearning AMI  | <https://docs.aws.amazon.com/dlami/latest/devguide/distributed-training.html> |
|          | 2    | 亚马逊SageMaker         | <https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/sagemaker-rl-distributed.html> |
|          | 3    | 微软Azure机器学习平台   | <https://docs.microsoft.com/zh-cn/azure/machine-learning/concept-distributed-training> |
|          | 4    | NVIDIA深度学习训练      | <https://www.nvidia.cn/deep-learning-ai/solutions/training/> |
|          | 5    | Seldon Core             | <https://docs.seldon.io/projects/seldon-core/en/v1.1.0/graph/distributed-tracing.html> |
|          | 6    | Intel AI                | <https://www.intel.com/content/www/us/en/artificial-intelligence/overview.html> |
|          | 7    | google AI cloud         | https://cloud.google.com/products/ai/                        |
|          | 8    | uber 米开朗琪罗         | https://eng.uber.com/                                        |

## 二、分布式训练产品功能点

|                            | DAS  | Lambda | UCloud | ModelArts | PAI  |      |      |      |      |
| :------------------------: | :--: | :----: | :----: | :-------: | :--: | ---- | ---- | ---- | ---- |
|       Tensorflow框架       |  ✔   |   ✔    |   ✔    |           |      |      |      |      |      |
|        Pytorch框架         |  ✔   |   ❌    |   ❌    |           |      |      |      |      |      |
| 控制台界面（创建训练任务） |  ❌   |   ✔    |   ✔    |           |      |      |      |      |      |
|     Jupyterlab开发环境     |  ✔   |   ❌    |   ❌    |           |      |      |      |      |      |
|         命令行实现         |  ❌   |   ❌    |   ✔    |           |      |      |      |      |      |

## 三、分布式训练竞品分析

### DAS

#### 主要逻辑和使用流程

在不同环节有疑问的地方，可写出

DAS数据算法平台支持在Jupterlab环境中实现Tensorflow/Pytorch/XGBoost下基于CPU/GPU集群的多架构分布式训练

1. 实现功能
   1. Tensorflow框架下支持基于GPU集群的ps架构及all-reduce架构分布式训练（对于基于CPU集群的两种策略的实现，只要不指定train_gpu_count即可）
   2. Pytorch框架下支持基于CPU集群及GPU集群的master_worker策略的分布式训练
   3. XGBoos基于GPU集群的分布式训练
2. 实现逻辑
   1. 数据上传及存储模块（支持三种方式，根据实际情况任选一种）
      1. 从大数据集市上拉取数据
      2. 对象存储服务拉取数据及保存数据
      3. 本地数据上传至开发环境
   2. 平台开发模块：开发环境中调用DAS API进行模型参数配置及训练。DAS API封装了实现各框架下分布式训练的方法并统一放置在das下的各个类中，根据框架及策略指定不同参数实例化类后开始训练
3. 使用流程
   1. 依靠数据存储服务拉取数据集或本地上传
   2. 原训练脚本添加集群配置并上传
   3. 调用DAS API进行诸如数据集路径、分布式模式、训练脚本文件路径、框架版本号、所使用的最大GPU数目等参数的指定
   4. 指定任务名称，进行模型训练
4. 配套功能
   1. jupterlab开发环境：支持对以上训练任务进行任务查看，包括查看分布式任务日志及其各实例的状态
   2. 控制台界面：支持分布式任务日志查看、性能监控及任务删除操作

#### 产品优势

1. 支持在Jupyterlab中交互式的进行模型训练任务的创建、训练及查看，对开发者友好
2. 使用DAS API统一封装各种框架下的各种架构，用户只需要选择使用何种架构，而不需要关注底层实现细节

#### 产品劣势

1. 分布式训练只支持任务查看，不支持任务创建，用户体验较差

#### 未来发展思路

1. Tensorflow中ring all-reduce架构采用的分布式训练框架horovod支持一个worker多GPU，提升训练速度
2. 数据上传及存储模块（支持共享存储池及非共享存储池的选择）

#### 可借鉴点

1. 使用API封装实现各框架下分布式训练的方法并统一放置在各个类中，根据框架及策略指定不同参数实例化类后开始训练，这种方式方便命令行及交互式开发环境中简化训练流程，但是要注意不同类中参数的指定

### Lambda

#### 主要逻辑和使用流程

Lambda平台支持在前台页面上实现基于Tensorflow框架下基于CPU/GPU集群的ps架构分布式训练

1. 实现功能：Tensorflow框架下支持基于CPU集群的ps架构分布式训练（只在生产环境中支持基于GPU集群的分布式训练）
2. 实现逻辑
   1. 数据上传及存储模块：存储输入所需数据集，模型训练过程产生的数据及输出模型。支持共享存储池及非共享存储池的选择，共享存储池支持==多点挂载==（分布式训练必选）
   2. 控制台界面任务创建模块：创建分布式训练任务，配置模型训练数据集路径（支持仓库拉取及存储池拉取方式），模型训练镜像，训练命令（训练脚本及训练轮数），预估时长，是否开启TensorBoard，ps节点及worker节点个数选择等参数
3. 使用流程
   1. 新建共享存储池，上传数据集
   2. 新建训练任务，配置系列参数，选择分布式训练配置节点个数，点击完成
   3. 点击执行训练任务，选择集群，选择存储卷保存模型训练中间数据及训练结束模型文件，进入排队序列中等待被执行

#### 产品优势

1. 分布式训练中提供预估时长选择，超过时长进行报警，避免训练一直进行（如未达到训练最大步数导致难以停止）
2. 实时查看容量使用状态，支持在线扩容
3. 提供应用监控服务

#### 产品劣势

1. 镜像少，支持框架少
2. 使用的ps策略比较陈旧，没有规避掉其中存在的负载不均衡、带宽限制及资源浪费问题
3. 不支持交互式环境开发，代码调试只能在本地进行
4. 使用环境不稳定（容易打不开），排队等待时间长

#### 未来发展思路



#### 可借鉴点

1. 创建训练作业界面指定使用何种架构，对应架构下选择不同类型节点个数，直接进行模型训练（封装）
2. 针对可能存在的训练作业时长过长的情况（占用过多资源或存在bug导致），可以选择让用户进行时长预估或平台自己停止用户的任务并对用户进行告警提示

### UCloud AI

UCloud训练服务支持在前台页面或命令行实现Tensorflow/MXNet下基于CPU/GPU集群的ps架构分布式训练

#### 主要逻辑和使用流程

1. 实现功能
   1. Tensorflow框架下支持基于CPU同GPU（共同运作，保证ps:worker=1:1）集群的ps架构分布式训练
   2. MXNet框架下支持基于CPU同GPU集群的DMLC分布式机器学习架构的分布式训练
2. 实现逻辑
   1. 数据上传及存储模块：使用对象存储服务上传训练所需的数据集、脚本文件
   2. 控制台界面任务创建模块：选择分布式环境模式，选择节点类型（单卡/多卡），选择训练相关参数（输入数据源、输出数据源、训练执行命令等）
3. 使用流程
   1. 创建存储池，下载存储池操作工具，上传数据（命令行上传）
   2. 单机版训练脚本本地修改并上传
   3. 控制台界面点击新建训练任务，配置基础信息及训练参数，配置完成点击确认开始训练或本地python命令行创建新的训练任务，指定分布式训练参数（节点个数、模型输入数据源、输出数据源等）
4. 配套功能
   1. 控制台界面访问任务Tensorboard
   2. 命令行实时日志输出
   3. 命令行查询TensorBoard URL

#### 产品优势

1. 提供云主机，用户可以在申请的云主机上实现本地命令行下的模型训练
2. 所有镜像文件都需要在云主机上安装完docker后自行创建，需要打包镜像到其提供的仓库上，使镜像定义更加灵活（自定义）
3. 创建训练任务需提交存储数据访问许可，数据使用更安全

#### 产品劣势

1. 不支持交互式环境开发，只能本地修改代码
2. 不提供预置镜像文件，所有镜像文件都需要在云主机上安装完docker后自行创建，用户使用不够友好
3. 很多操作只能在命令行进行，控制台界面却不行，比如上传数据文件到存储池

#### 未来发展思路

1. 支持Tensorflow框架下ring all-reduce架构的分布式训练
2. 扩展Pytorch框架下的分布式训练实现

#### 可借鉴点

1. 使用数据存储服务时提交数据访问许可，保证数据使用的安全性
2. 支持自定义镜像服务（命令行与控制台界面两种方式）

### PAI

#### 主要逻辑和使用流程

#### 产品优势

#### 产品劣势

#### 未来发展思路

#### 可借鉴点

### ModelArts

#### 主要逻辑和使用流程

#### 产品优势

#### 产品劣势

#### 未来发展思路

#### 可借鉴点

## 四、总结



### 



