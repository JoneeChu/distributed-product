

| 类别 | 序号 | 平台（产品）名称 | 产品状况 | 网址 | 描述 |
| --- | --- | --- | --- | --- | --- |
|国内产品|1|华为AI开发平台ModelArts|详细|<https://support.huaweicloud.com/tg-modelarts/modelarts_15_0007.html>|面向开发者的一站式AI开发平台，为机器学习与深度学习提供海量数据预处理及半自动化标注、大规模分布式Training、自动化模型生成，及端-边-云模型按需部署能力，帮助用户快速创建和部署模型，管理全周期AI工作流|
||2|华为云容器实例CCI|较为详细|<https://support.huaweicloud.com/api-cci/cci_02_3141.html>|提供 Serverless Container（无服务器容器）引擎，让您无需创建和管理服务器集群即可直接运行容器|
||3|阿里机器学习平台PAI|详细|<https://help.aliyun.com/document_detail/165137.html?spm=a2c4g.11186623.6.658.3561395frfXWth>|PAI-DLC（Deep Learning Containers）是基于阿里巴巴容器服务ACK（Alibaba Cloud Container Service for Kubernetes）的深度学习训练平台，为您提供灵活、稳定、易用和极致性能的深度学习训练环境|
||4|UCloud AI训练服务平台|详细|<https://docs.ucloud.cn/uai-train/introduction/distributed-job>|采用Parameter Server和Worker Server混部的方法，所有计算节点均由GPU物理云主机组成。PS 仅使用CPU进行计算，Worker Server则同时使用GPU和CPU进行计算，PS 和 Worker的比例为1:1|
||5|腾讯智能钛机器学习平台|较为详细|<https://cloud.tencent.com/document/product/851/40124>|TI SDK 是腾讯云智能钛机器学习平台 TI-ONE 提供的开源软件包，让用户可以通过代码（SDK/API）向 TI-ONE 提交机器学习和深度学习的训练任务|
||6|美团云深度学习平台|不具体|<https://www.mtyun.com/doc/products/ai/dls/TensorFlow-distribution>|基于Tensorflow实现多机多卡分布式训练|
||7|小米生态云深度学习平台|不具体|<http://docs.api.xiaomi.com/zh/cloud-ml/trainjob/0501_use_distributed_training.html>|Xiaomi Cloud-ML支持标准的分布式TensorFlow应用，用户只需编写对应的Python脚本即可提交运行，用法与单机版类似|
||8|百度飞浆|非产品|<https://www.paddlepaddle.org.cn/documentation/docs/zh/api_guides/low_level/distributed/index.html> |飞浆分布式训练说明文档|
||9|才云分布式学习平台|无文档|<https://caicloud.io/methods/distributed?word_con=A2>|将企业的硬件和人力资源转化为计算和业务运营管理能力，提供从数据处理、模型训练到服务托管的一站式服务|
||10|浪潮AIStation 训练平台|无文档无分布式训练|<https://www.inspur.com/lcjtww/2315499/2315503/2378047/2378048/2378054/2378932/index.html>||
||11|百度机器学习BML|较详细|<https://cloud.baidu.com/doc/BML/s/pjxbisnm8>|提供了高性能的集群训练环境，多种主流算法框架与海量模型案例|
||12|京东-DAS平台|理论较为详细|https://cf.jd.com/pages/viewpage.action?pageId=246116591|实现tf的ps与all-reduce两种分布式训练方法，提供pytorch的cpu与GPU两种分布式训练方法|
||13|京东-Lambda平台|网站不可用|https://lambda.jd.com||
||14|滴滴云|无分布式训练|https://www.didiyun.com/||
|国外产品|1|亚马逊Deeplearning AMI|详细|<https://docs.aws.amazon.com/dlami/latest/devguide/distributed-training.html>|多GPU MXNet框架训练|
||2|亚马逊SageMaker|较为详细|<https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/sagemaker-rl-distributed.html>|支持多核和多实例分布式训练|
||3|微软Azure机器学习平台|不具体|<https://docs.microsoft.com/zh-cn/azure/machine-learning/concept-distributed-training>||
||4|NVIDIA深度学习训练|无文档|<https://www.nvidia.cn/deep-learning-ai/solutions/training/>|从桌边到云端和数据中心进行深度学习训练|
||5|Seldon Core|未出现分布式训练|<https://docs.seldon.io/projects/seldon-core/en/v1.1.0/graph/distributed-tracing.html>||
||6|Intel AI|硬件加速|<https://www.intel.com/content/www/us/en/artificial-intelligence/overview.html>||
||7|google AI cloud|详细|https://cloud.google.com/products/ai/||
||8|uber 米开朗琪罗|是工程实践项目|https://eng.uber.com/||
|国内框架|1|百度飞浆||<https://github.com/PaddlePaddle/Fleet>|飞浆分布式训练API|
||2|字节跳动BytePs||<https://github.com/bytedance/byteps>|高性能分布式训练框架|
||3|小米生态云深度学习框架mace||<https://github.com/XiaoMi/mace>||
||4|腾讯Angel||<https://github.com/Angel-ML/angel>|全栈机器学习平台|
||5|Arena||||
|国外框架|1|谷歌tensorflow||<https://tensorflow.google.cn/tutorials/distribute/custom_training>|低阶API或高阶API，预创建或自定义实现单机多卡或多机多卡分布式训练|
||2|Facebook pytorch||<https://pytorch.apachecn.org/docs/1.4/34.html>|实现并行与分布式训练|
||3|亚马逊keras-apache-mxnet||<https://github.com/awslabs/keras-apache-mxnet>||
||4|Horovod||https://github.com/horovod/horovod|一种应用于Tensorflow/pytorch/keras/mxnet的分布式深度学习框架|
||5|tf-operator||https://github.com/kubeflow/tf-operator|FJob提供了一个Kubernetes自定义资源，它使得在Kubernetes上轻松运行分布式或非分布式TensorFlow作业|
||6|kubeflow/arena||https://github.com/kubeflow/arena|Arena是一个命令行界面，供数据科学家运行和监视机器学习训练任务，并以一种简单的方式检查其结果。目前它支持solo/distributed TensorFlow训练|
